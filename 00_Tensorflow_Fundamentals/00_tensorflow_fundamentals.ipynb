{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we're going to cover some of the most fundaental concepts of tensors using Tensorflow\n",
    "\n",
    "More specifically, we're going to cover:\n",
    "* Introduction to tensors\n",
    "* Getting information from tensors\n",
    "* Manipulating tensors\n",
    "* Tensors & NumPy\n",
    "* Using @tf.function (a way to speed up your regular Python functions)\n",
    "* Exercoses to try for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp39-cp39-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0; platform_system == \"Windows\"\n",
      "  Downloading tensorflow_intel-2.18.0-cp39-cp39-win_amd64.whl (390.0 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\capma\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0; platform_system == \"Windows\"->tensorflow) (24.2)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.12.1-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\capma\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0; platform_system == \"Windows\"->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.17.0-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.68.0-cp39-cp39-win_amd64.whl (4.4 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-5.29.0-cp39-cp39-win_amd64.whl (434 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Downloading ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1; python_version < \"3.12\"\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting numpy<2.1.0,>=1.26.0\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\capma\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0; platform_system == \"Windows\"->tensorflow) (4.12.2)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\capma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.18.0; platform_system == \"Windows\"->tensorflow) (49.2.1)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.13.1-cp39-cp39-win_amd64.whl (277 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\capma\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0; platform_system == \"Windows\"->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\capma\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0; platform_system == \"Windows\"->tensorflow) (8.5.0)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\capma\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0; platform_system == \"Windows\"->tensorflow) (3.21.0)\n",
      "Installing collected packages: libclang, numpy, h5py, certifi, idna, urllib3, charset-normalizer, requests, ml-dtypes, namex, mdurl, markdown-it-py, rich, optree, absl-py, keras, google-pasta, termcolor, grpcio, markdown, MarkupSafe, werkzeug, tensorboard-data-server, protobuf, tensorboard, wrapt, flatbuffers, tensorflow-io-gcs-filesystem, gast, opt-einsum, wheel, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.8.30 charset-normalizer-3.4.0 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 h5py-3.12.1 idna-3.10 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.0 requests-2.32.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 urllib3-2.2.3 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 20.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors with tf.constant()\n",
    "scalar = tf.constant(7) # creates a constant tensor with the value 7\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of a tensor (ndim stands for number of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector\n",
    "vector = tf.constant([10,10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension of our vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix (has more than 1 dimension)\n",
    "matrix = tf.constant([[10,7],\n",
    "                      [7,10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ndim` returns us the dimension our arrays are in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another matrix\n",
    "another_matrix = tf.constant([[10.,7.],\n",
    "                              [3.,2.,],\n",
    "                              [8.,9.,]], dtype = tf.float16) # specify the data type with dtype parameters\n",
    "\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we have `float16` and `int32`. The number after the word means the number of bits it takes up to store the number. Lower bits means lower space to take up to store a value.\n",
    "\n",
    "`16-bit` - values from -65,504 to 65,504, particularly used for deep learning and fast computation due to lower memory usage.\n",
    "\n",
    "`32-bit` - values from -2,147,483,648 to 2,147,483,647, common for counting and inexing/categorizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the number dimensions of another_matrix\n",
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "tensor = tf.constant([[[1,2,3,],\n",
    "                       [4,5,6]],\n",
    "                       [[7,8,9],\n",
    "                        [10,11,12]],\n",
    "                        [[13,14,15],\n",
    "                         [16,17,18]]])\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've created so far:\n",
    "* Scalar: a single number\n",
    "* Vector: a number with direction (e.g. wind speed and direction)\n",
    "* Matrix: a 2-dimensional array of numbers\n",
    "* Tensor: an n-dimensional aray of numbers (where n can be any number, a 0-dimensional tensor is a scalar, a 1 dimensional tensor is a vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors with `tf.Variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the same tensor with tf.Variable() as above\n",
    "changeable_tensor = tf.Variable([10,7])\n",
    "unchangeable_tensor = tf.constant([10,7])\n",
    "changeable_tensor, unchangeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Let's try change one of the elements in our changeable tensor\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mchangeable_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m      3\u001b[0m changeable_tensor\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Let's try change one of the elements in our changeable tensor\n",
    "changeable_tensor[0] = 7\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([7, 7], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about we try .assign()\n",
    "changeable_tensor[0].assign(7)\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Let's try change our unchangeable tensor\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43munchangeable_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m(\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m      3\u001b[0m unchangeable_tensor\n",
      "File \u001b[1;32mc:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:260\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    254\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    255\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    256\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "# Let's try change our unchangeable tensor\n",
    "unchangeable_tensor[0].assign(7)\n",
    "unchangeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should you choose between `constant` or `variable`?\n",
    "\n",
    "That depends on your problem, though most of the time, TensorFlow automatically picks one for you. (When loading/modelling data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating random tensors\n",
    "\n",
    "Random tensors, are arbitrary values that contain numbers. But why would we want randomized tensors?\n",
    "\n",
    "This is to initialize weights (patterns), where the neural networks use as a starting point to learn the data.\n",
    "\n",
    "They take the randomized data, and start refining them bit by bit, as they learn and understand the patterns of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How a network learns:\n",
    "![](00-how-a-network-learns.png)\n",
    "\n",
    "*Networks learn from random patterns (1) then going through provided data (2) whilt updating its randomized patterns, to represent provided data*\n",
    "\n",
    "We can create random tensors by using the `tf.random.Generator` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random, but same tensors\n",
    "random_1 = tf.random.Generator.from_seed(42) # set seed for reproducibility\n",
    "random_1 = random_1.normal(shape=(3,2)) # create tensor from a normal distribution\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3,2))\n",
    "\n",
    "# Are they equal?\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its not truly random, but pseudorandom. The randomness of numbers are controlled by the `seed`. This allows consistency in random numbers when we need it, such as comparing 2 different ML models.\n",
    "\n",
    "So setting the same `seed` for the data, will give us the same set of randomized number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[ 0.27305737, -0.29925638],\n",
       "        [-0.3652325 ,  0.61883307],\n",
       "        [-1.0130816 ,  0.28291714]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[False, False],\n",
       "        [False, False],\n",
       "        [False, False]])>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random and different tensors\n",
    "random_3 = tf.random.Generator.from_seed(42)\n",
    "random_3 = random_3.normal(shape=(3,2))\n",
    "random_4 = tf.random.Generator.from_seed(11)\n",
    "random_4 = random_4.normal(shape=(3,2))\n",
    "\n",
    "# Check tensors if equal\n",
    "random_3, random_4, random_3 == random_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about shuffling the order of tensors?\n",
    "\n",
    "This is useful, for example a case scenario, where you have 15,000 images of cats and dogs. However, the first 10,000 photos are cats, and the last 5,000 are dogs. The order of the images may affect the neural network's learning, as it might put too much focus on order of images, and predicting the front photos as cats.\n",
    "\n",
    "So sometimes its good to shuffle things around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 2,  5],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling a tensor\n",
    "not_shuffled = tf.constant([[10,7],\n",
    "                            [3,4],\n",
    "                            [2,5]])\n",
    "# Getting a different result every time you run this code\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle randomly but in the same order, through seed (but won't actually be the same)\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why didn't the seed apply?\n",
    "\n",
    "Because of the 4th rule in set_seed() documentation. `tf.random.set_seed(42)` sets the global seed, and therefore the seed parameter can be used in `tf.random.shuffle(seed=42)`.\n",
    "\n",
    "\"Operations relying on random seeds are driven from two seeds: the global and operation-level seeds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle in same order, set global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set the operation random seed\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as often used, you can create `tf.ones()` to create tensors full of ones, and `tf.zeros()` for tensors full of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(shape=(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(shape=(3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays are convertible to tensors.\n",
    "\n",
    "NOTE:\n",
    "Main difference between tensors and NumPy arrays is that tensors can use GPU, making neural network processing much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24], dtype=int32),\n",
       " <tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15],\n",
       "         [16, 17, 18],\n",
       "         [19, 20, 21],\n",
       "         [22, 23, 24]]], dtype=int32)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_A= np.arange(1, 25, dtype=np.int32) # create NumPy array from 1 to 25, exclusive\n",
    "A = tf.constant(numpy_A,\n",
    "                shape=[2,4,3]) # note the shape total (2*4*3) has to match number of elements in the array\n",
    "numpy_A, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from tensors (shape, rank, size)\n",
    "\n",
    "There are times where you want speciic pieces of infomations form your tensors, such as:\n",
    "* **Shape**: The length (number of elements) of each of the dimensions of a tensor\n",
    "* **Rank**: The number of tensor dimensions. Scalar = 0, Vector = 1, Matrix = 2, Tensor = x (any amount)\n",
    "* **Axis** or **Dimension**: A particular dimension of a tensor.\n",
    "* **Size**: The total number of items in the tensor.\n",
    "\n",
    "These are used, when lining up the shape of the data to the shape of your model. Such as making sure the shape of your image tensors, are the same shape as your model's input layer.\n",
    "\n",
    "Mismatch in shape causes errors, or inefficient processing in the neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen the use of `ndim` attribute, let's see the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 tensor (4 dimensions)\n",
    "rank_4_tensor = tf.zeros([2,3,4,5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element: <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "Elements along axis(index) 0 of tensor: 2\n",
      "Elements along last axis(index) of tensor: 5\n",
      "Total number of elements (2*3*4*5) 120\n"
     ]
    }
   ],
   "source": [
    "# Get various attributes of tensor\n",
    "print('Datatype of every element:', rank_4_tensor.dtype)\n",
    "print('Number of dimensions (rank):', rank_4_tensor.ndim)\n",
    "print('Shape of tensor:', rank_4_tensor.shape)\n",
    "print('Elements along axis(index) 0 of tensor:', rank_4_tensor.shape[0])\n",
    "print('Elements along last axis(index) of tensor:', rank_4_tensor.shape[-1])\n",
    "print('Total number of elements (2*3*4*5)', tf.size(rank_4_tensor).numpy()) # .numpy() converts to NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also index tensors just like Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 2 items of each dimension\n",
    "rank_4_tensor[:2, :2, :2, :2] # retriees from index 0 to 1, excludes 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dimension from each index except for the final one\n",
    "rank_4_tensor[:1,:1,:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
       "array([[10],\n",
       "       [ 3]], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 2 tensor (2 dimensions)\n",
    "rank_2_tensor = tf.constant([[10,7],\n",
    "                             [3,4]])\n",
    "\n",
    "# Get the last item of each row\n",
    "rank_2_tensor[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to add dimensions, whilst keeping the same data present, use `tf.newaxis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       " array([[[10],\n",
       "         [ 7]],\n",
       " \n",
       "        [[ 3],\n",
       "         [ 4]]], dtype=int32)>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension (to the end)\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis] # '...' > in Python means 'all dimensions prior to'\n",
    "rank_2_tensor, rank_3_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `tf.newaxis` makes a new dimension, past all the other present dimensions, due to the rule `...`\n",
    "\n",
    "You can achieve the same using `tf.expand_dims()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=-1) # adding it at last row with axis/index -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)\n",
    "\n",
    "Finding patterns in tensors (numerical representation of data) requires manipulaing them.\n",
    "\n",
    "Again, when building models in TensorFlow, much of this pattern discovery is done for you.\n",
    "\n",
    "\n",
    "### Basic operations\n",
    "\n",
    "You can perform basic mathematical operations like + , -, * directly onto the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can add values to a tensor uding the addition operator\n",
    "tensor = tf.constant([[10,7], [3,4]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used `tf.constant()`, the original tensor is unchanged. The addition is done on a separate copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try other operators as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]], dtype=int32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[5. , 3.5],\n",
       "       [1.5, 2. ]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an equivalent to these operators, called TensorFlow function. Use it wherever possible, as it performs much quicker than the operators above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tensorflow function, equivalent to *\n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the original tensor is still unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "A common operation thats used is the `matrix multiplication`. Its implemented with `tf.matmul()`.\n",
    "\n",
    "There two main rules to be aware of:\n",
    "\n",
    "1. The inner dimensions must match:\n",
    "* (3,5) @ (3.5) won't work\n",
    "* (5,3) @ (3,5) will work\n",
    "* (3,5) @ (5,3) will work\n",
    "\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    "* (5,3) @ (3,7) -> (5,7)\n",
    "* (3,5) @ (5,3) -> (3,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication in TensorFlow\n",
    "print(tensor)\n",
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]], dtype=int32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication with pythn operator '@'\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, it's not multiplying in the way I was expecting. 10*10 should be 100 right? Why is there 121?\n",
    "\n",
    "There's an explanation to the way they multiply two different tensors:\n",
    "![](matrix-multiplication.png)\n",
    "\n",
    "we got our two tensors, \n",
    "\n",
    "10, 7 | 10, 7\n",
    "\n",
    " 3, 4 | 3, 4\n",
    "\n",
    "turn tensor 1, 90 degrees clockwise\n",
    "\n",
    "3, 10 | 10, 7\n",
    "\n",
    " 4, 7 | 3, 4\n",
    "\n",
    " then multiply the inner number together: *10 * 10 , 7 * 3*\n",
    " \n",
    " then the inner numbers from tensor 1, to outer tensor 2: *10 * 7 , 7 * 4*\n",
    "\n",
    " then do the other side of tensor 1, with inner tensor 2: *3 * 10 , 4 * 3*\n",
    "\n",
    " and again to the outer tensor 2: *3 * 7 , 4 * 4*\n",
    "\n",
    " Here's another graphic from the course, in a more appealing way:\n",
    " ![](00-lining-up-dot-products.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create tensors that are mismatched shapes, unlike the one above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]], dtype=int32)>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create (3,2) tensor\n",
    "X = tf.constant([[1,2],\n",
    "                 [3,4],\n",
    "                 [5,6]])\n",
    "\n",
    "# Another (3,2) tensor\n",
    "Y = tf.constant([[7,8],\n",
    "                 [9,10],\n",
    "                 [11,12]])\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Try to matrix multiply them\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul] name: "
     ]
    }
   ],
   "source": [
    "# Try to matrix multiply them\n",
    "X @ Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why doesn't it work, well because the inner dimensions don't match each other. Since we've learnt how matrixes multiply, it helps us understand why they won't work with each other.\n",
    "\n",
    "1, 2 | 7, 8\n",
    "\n",
    "3, 4 | 9, 10\n",
    "\n",
    "5, 6 | 11, 12\n",
    "\n",
    "Now let's perform the 90 degree clockwise flip method on tensor 1.\n",
    "\n",
    "5, 3, 1 | 7, 8\n",
    "\n",
    "6, 4, 2 | 9, 10\n",
    "\n",
    "| 11, 12\n",
    "\n",
    "We have a problem where we dont have values for the 3rd row to multiply with!\n",
    "\n",
    "Now we know why it doesn't work, we need to reshape it, so it fits the rules:\n",
    "* `tf.reshape()` - allows us to reshape a tensor into a defined shape\n",
    "* `tf.transpose()` - switches the dimensions of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 7,  8,  9],\n",
       "       [10, 11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of reshape (3,2) > (2,3)\n",
    "tf.reshape(Y, shape=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try matrix multiplication with reshaped Y\n",
    "X @ tf.reshape(Y, shape=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with X instead, and using `tf.transpose()` and `tf.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of transpose (3,2) > (2,3)\n",
    "tf.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try matrix multiplification\n",
    "tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can do the sae with parameters/booleans\n",
    "tf.matmul(a=X, b=Y, transpose_a=True, transpose_b=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how our transposition/reshaping of `X` and `Y` changes the results? It's because of rule 1, the inner values must be the same\n",
    "\n",
    "* `(3,2) @ (2,3)` > `(3,3)` due to reshaping `Y`\n",
    "* `(2,3) @ (3,2)` > `(2,2)` due to reshaping `X`\n",
    "\n",
    "Data manipulation reminder:\n",
    "You'll spend lots of time in machine learning, working with neural networks, reshaping data and preparing it for various operations.\n",
    "\n",
    "### The dot product\n",
    "\n",
    "Multiplying matrices with each over, can also be referred as the dot product.\n",
    "\n",
    "You can perform `tf.matmul()` operation using `tf.tensordot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the dot product on X and Y (we'll transpose X so it won't cause errors)\n",
    "tf.tensordot(tf.transpose(X), Y, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite `reshape` and `transpose` do very similar jobs, the output when you multiply the matrices is different, after performing these two functions.\n",
    "\n",
    "Let's see these in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]], dtype=int32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform matrix multiplication between X and Y (transposed)\n",
    "tf.matmul(X, tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform matrix multiplication between X and Y (reshaped)\n",
    "tf.matmul(X, tf.reshape(Y, (2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically the reshaping should result in the same outcome, as we're only reshaping only one of the tensors. Something must be going on between the two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 2]), TensorShape([2, 3]), TensorShape([2, 3]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shaped of Y, reshaped Y and transposed Y\n",
    "Y.shape, tf.reshape(Y, (2,3)).shape, tf.transpose(Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure we got the same shape between the two functions. How about the values within Y after its been reshaped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Y:\n",
      "tf.Tensor(\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]], shape=(3, 2), dtype=int32) /n\n",
      "Y reshaped to (2,3):\n",
      "tf.Tensor(\n",
      "[[ 7  8  9]\n",
      " [10 11 12]], shape=(2, 3), dtype=int32) /n\n",
      "Y transposed:\n",
      "tf.Tensor(\n",
      "[[ 7  9 11]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Check values of Y, reshape Y and transposed Y\n",
    "print('Normal Y:')\n",
    "print(Y, '/n') # '/n' means new line\n",
    "\n",
    "print('Y reshaped to (2,3):')\n",
    "print(tf.reshape(Y, (2,3)), '/n')\n",
    "\n",
    "print('Y transposed:')\n",
    "print(tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite producing the same shaped, they organize the values within them differently. This can be explained by their method of choice:\n",
    "\n",
    "* `tf.reshape()` - change the shape of the given tensor first, then inserting the values in order (from lowest, to highest index, and continuing for the next set in other dimensions. [[7,8], [9,10], [11,12]])\n",
    "\n",
    "* `tf.tranpose()` - swap the order of the axes, aka performing a 90degree clockwise shift of the values.\n",
    "\n",
    "So which to use?\n",
    "\n",
    "The thing is, these operations are automatically chosen for you while training your neural networks. But generally, its up to you on which function you'd like to use.\n",
    "\n",
    "### Matrix multiplication tidbits\n",
    "\n",
    "* If we transposed `Y`, it would be represented as `Y^T` (^T represents transpose).\n",
    "\n",
    "* There's a hands-on demo of matrix multiplication: [http://matrixmultiplication.xyz/](http://matrixmultiplication.xyz/)\n",
    "\n",
    "![](00-matrix-multiply-crop.gif)\n",
    "\n",
    "Again it shows us how we flip 90 degrees on one tensor. For tensor 2, you counterclockwise the flip, and get your results in ordern from left to right, top to bottom.\n",
    "\n",
    "### Changing the datatype of a tensor\n",
    "\n",
    "Sometimes, you want to alter the default datatype of your tensor.\n",
    "\n",
    "This is common if you want to compute something with less precision, say a 16-bit float, rather than the default 32-bit float.\n",
    "\n",
    "This is useful if computer capacity for you is a luxury, such as on old pcs or phones.\n",
    "\n",
    "You can change datatype of tensor with `tf.cast()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a new tensor with default datatype (float32)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m B \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;241m1.7\u001b[39m,\u001b[38;5;241m7.4\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a new tensor with default datatype (int32)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m C \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m7\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a new tensor with default datatype (float32)\n",
    "B = tf.constant([1.7,7.4])\n",
    "\n",
    "# Create a new tensor with default datatype (int32)\n",
    "C = tf.constant([1,7])\n",
    "B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from float32 to float16\n",
    "B = tf.cast(B, dtype=tf.float16)\n",
    "B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change form int32 to float32\n",
    "C = tf.cast(C, dtype=tf.float32)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting absolute values\n",
    "\n",
    "`tf.abs()` gets all the values to default positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ -7, -10], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor with negative values\n",
    "D = tf.constant([-7,-10])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10], dtype=int32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the absolute values\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum (aggregation)\n",
    "You can quickly aggregate (perform calculations on the whole tensor) the tensor, to find things like min, max, mean, sum, etc.\n",
    "\n",
    "To perform those actions, the methods have this syntax: `reduce()_[action]`, such as:\n",
    "* `tf.reduce_min()`\n",
    "* `tf.reduce_max()`\n",
    "* `tf.reduce_mean()`\n",
    "* `tf.reduce_sum()`\n",
    "\n",
    "Their method name's should be pretty self explanatory on what they perform\n",
    "\n",
    "**NOTE**: They are typically labeled under the `math` module, e.g. `tf.math.reduce_min()`, but can still be used under its alias, `tf.reduce_min()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([47, 98, 72, 18, 67, 29, 57, 67, 22, 36, 93, 46, 88, 92, 46, 10, 68,\n",
       "       35, 55, 10, 73, 37, 20, 75, 10, 35,  9, 78, 86, 30, 19, 49, 91, 36,\n",
       "       90, 77, 66, 59, 20, 23, 95, 49,  1, 12, 31, 56, 73,  8, 89, 16],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with 50 random values between 0 and 100\n",
    "E = tf.constant(np.random.randint(low=0, high=100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=98>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum\n",
    "tf.reduce_max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=49>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean\n",
    "tf.reduce_mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2469>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "tf.reduce_sum(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find the standard deviation `tf.reduce_std()` and variance `tf.reduce_variance()` of elements in a ensor uding similar methods.\n",
    "\n",
    "### Finding the positional maximum and minimum\n",
    "\n",
    "Say we want to find the position of the maximum value in a tensor.\n",
    "\n",
    "This is helpful, when you want to line up your labels, like `['Green', 'Blue', 'Red']` with your prediction probabilities tensor `[0.98, 0.01, 0.01]`.\n",
    "\n",
    "In this case, the predicted label (the one with the highest prediction probability) is `Green`. Though we won't always know the predicted label by looking at the prediction probabilities only. Thus we have the positional to help us find it.\n",
    "\n",
    "You can do the same for minimum with the following:\n",
    "\n",
    "`tf.argmax()` - find the max element's position\n",
    "`tf.argmim()` - find the min element's position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
       "array([0.48551008, 0.82747985, 0.90730265, 0.34506211, 0.03348001,\n",
       "       0.69003013, 0.65052136, 0.34591901, 0.85289438, 0.13253629,\n",
       "       0.39117839, 0.06870841, 0.64977751, 0.19646184, 0.6061449 ,\n",
       "       0.53312323, 0.25243483, 0.69895809, 0.25888549, 0.22285226,\n",
       "       0.72302091, 0.19667219, 0.23853042, 0.26310526, 0.01228497,\n",
       "       0.97211127, 0.09810491, 0.66451587, 0.5948059 , 0.37632583,\n",
       "       0.27540981, 0.86569755, 0.11427361, 0.19401338, 0.43201752,\n",
       "       0.77977753, 0.32247213, 0.60696442, 0.28119469, 0.15859664,\n",
       "       0.91636374, 0.71994465, 0.74919283, 0.9307283 , 0.01533177,\n",
       "       0.38774824, 0.02033448, 0.21588216, 0.98796492, 0.79500156])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with 50 values between 0 and 1\n",
    "F = tf.constant(np.random.random(50))\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=48>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max element position in F\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=24>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min element position in F\n",
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value of F is at position: 48\n",
      "The maximum value of F is: 0.9879649201116832\n",
      "Using tf.argma() to index F, the maximum value of F is: 0.9879649201116832\n",
      "Now, are the two maxes the same? True\n"
     ]
    }
   ],
   "source": [
    "print(f'The maximum value of F is at position: {tf.argmax(F).numpy()}') #.numpy() > only taking the results shown in numpy\n",
    "print(f'The maximum value of F is: {tf.reduce_max(F).numpy()}')\n",
    "print(f'Using tf.argma() to index F, the maximum value of F is: {F[tf.argmax(F)].numpy()}') # [place index value here] aka the '48'\n",
    "print(f'Now, are the two maxes the same? {F[tf.argmax(F)].numpy() == tf.reduce_max(F)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezing a tensor (removing all single dimensions)\n",
    "\n",
    "If you need to remove single-dimensions from a tensor (dimensions with size 1), you can use `tf.squeeze()`, which removes all dimensions with a `1` from the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 1, 1, 1, 50]), 5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 5 (5 dimensions) tensor of 50 numbers between 0 to 100\n",
    "G = tf.constant(np.random.randint(0, 100, 50), shape=(1,1,1,1,50))\n",
    "G.shape, G.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]), 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze tensor G (remove all 1 dimensions)\n",
    "G_squeezed = tf.squeeze(G)\n",
    "G_squeezed.shape, G_squeezed.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "\n",
    "If you have tensor indixes, and want to one-hot encode it, use `tf.one_hot()`.\n",
    "\n",
    "Also you should specify the `depth` parameter. The level which you want to one-hot encode to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of indices\n",
    "some_list = [0,1,2,3]\n",
    "\n",
    "# One hot encode them\n",
    "tf.one_hot(some_list, depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify values for `on_value` and `off_value`, rather than 1 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b\"We're live!\", b'Offline', b'Offline', b'Offline'],\n",
       "       [b'Offline', b\"We're live!\", b'Offline', b'Offline'],\n",
       "       [b'Offline', b'Offline', b\"We're live!\", b'Offline'],\n",
       "       [b'Offline', b'Offline', b'Offline', b\"We're live!\"]], dtype=object)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify custom values for on and off encoding\n",
    "tf.one_hot(some_list, depth=4, on_value=\"We're live!\", off_value=\"Offline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squaring, log, square root\n",
    "\n",
    "There are many mathematical operations you'll perform with a project, and are likely to exist.\n",
    "\n",
    "We'll take a look at a few:\n",
    "* `tf.square()` - get the square of every value in a tensor\n",
    "* `tf.sqrt()` - get the square root of every value in a tensor (**Note**: the tensor has to be a float, or will return error).\n",
    "* `tf.math.log()` - get the natural log of every value in a tensor (elements also need to be floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor\n",
    "H = tf.constant(np.arange(1,10))\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square it\n",
    "tf.square(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find the squareroot\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\capma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt] name: "
     ]
    }
   ],
   "source": [
    "# Find the squareroot\n",
    "tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change H to float32\n",
    "H = tf.cast(H, dtype=tf.float32)\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([1.       , 1.4142135, 1.7320508, 2.       , 2.236068 , 2.4494898,\n",
       "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the log (input also needs to be float)\n",
    "tf.math.log(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating `tf.variable()` tensors\n",
    "\n",
    "Tensors with `tf.variable()` can be changed with the following methods:\n",
    "\n",
    "* `.assign()` - assign a different value to a given index, in a tensor.\n",
    "\n",
    "* `.assign_add()` - select the given index in the tensor, and add value onto it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5,) dtype=int64, numpy=array([0, 1, 2, 3, 4])>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a variable tensor\n",
    "I = tf.Variable(np.arange(0,5))\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int64, numpy=array([ 0,  1,  2,  3, 50])>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the final value with 50\n",
    "I.assign([0,1,2,3,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int64, numpy=array([10, 11, 12, 13, 60])>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 10 to every element in I\n",
    "I.assign_add([10,10,10,10,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy\n",
    "\n",
    "We've seen some examples of both NumPy arrays and Tensors interacting together, like using NumPy arrays to create tensors.\n",
    "\n",
    "Tensors can also be converted into NumPy arrays using:\n",
    "\n",
    "* `np.array()` - pas a tensor to convert to an ndarray (Numpy's main datatype)\n",
    "* `tensor.numpy()` - call on a tensor to convert to an ndarray.\n",
    "\n",
    "Doing this is helpful as it makes tensors iterable as well as allows us to use any of NumPy's methods on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from NumPy arrays\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor J to NumPy with np.array()\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conver tensor J to NumPy with .numpy()\n",
    "J.numpy(), type(J.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tensors have `dtype=float32`, where as NumPy is `dtype=float64`\n",
    "\n",
    "This is because, neural networks (which tends to be built with TensorFlow), generally works better with less precision, preffering 32-bit, over 64-bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create  tensor from NumPy and from an array\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.])) # will be float64\n",
    "tensor_J = tf.constant([3., 7., 10.]) # will be float32\n",
    "numpy_J.dtype, tensor_J.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `@tf.function`\n",
    "\n",
    "Through your TensorFlow journey, you might've come across this python function, with a decorator called `@tf.function`.\n",
    "\n",
    "What are python decorators?\n",
    "\n",
    "It's a design pattern, to allow for modification and extension of behaviours on a epcific function or method, without changing the actual code. They are often used for code reusability, or separation converns. Making it easy to add certain functionalities, like logging, timing, access control, etc.\n",
    "\n",
    "**How does a decorator work?**\n",
    "\n",
    "1. Takes another function as its input\n",
    "2. Wraps it with additional functionality\n",
    "3. Returns the wrapped function\n",
    "\n",
    "Here is a code snippet example. \n",
    "```python\n",
    "def sandwich_decorator(func):\n",
    "    def wrapper():\n",
    "        print(\" This is the top slice of bread.\")\n",
    "        func()\n",
    "        print(\" This is the bottom slice of bread.\")\n",
    "    return wrapper\n",
    "\n",
    "@sandwich_decorator\n",
    "def my_filling():\n",
    "    print(\" Heres the delicious filling!\")\n",
    "\n",
    "my_filling()\n",
    "```\n",
    "\n",
    "And it outputs:\n",
    "```\n",
    " This is the top slice of bread.\n",
    " Heres the delicious filling!\n",
    " This is the bottom slice of bread.\n",
    "```\n",
    "\n",
    "Pay attention to `@my_decorator` and `func()`.\n",
    "\n",
    "`@my_decorator` - Think of it as you calling a function in python, and the variable you're pulling into `@my_decorator`, is the function `say_hello()`. You got functionception!\n",
    "\n",
    "`func()` - This is the variable of `@my_decorator`, aka the function that was pulled into the decorator. The function will perform its action within the progression of the wrapper function.\n",
    "\n",
    "**TLDR**: Decorators are a lot like functions, but they sandwich the fillings with bread.\n",
    "\n",
    "Back to `@tf.function` decorator use, it turns a python function into a callable TensorFlow graph. Aka if you've written python functions, and you decorate it with `@tf.function`, when exporting the code, it will attempt to conver it into a faster version of itself, aka better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple function\n",
    "def function(x, y):\n",
    "    return x ** 2 + y\n",
    "\n",
    "x = tf.constant(np.arange(0,10))\n",
    "y = tf.constant(np.arange(10,20))\n",
    "function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create same function, but decorate it with tf.function\n",
    "@tf.function\n",
    "def tf_function(x, y):\n",
    "    return x ** 2 + y\n",
    "\n",
    "tf_function(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no difference between the two functions.\n",
    "\n",
    "Much of the difference happens behind the scenes. One of the main ones, is potential code speed-ups wherever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding access to GPUs\n",
    "\n",
    "We've mentions GPUs plenty of time within the notebook.\n",
    "\n",
    "So how to check if one's available?\n",
    "\n",
    "you can check if you have access to a GPU using `tf.config.list_physical_devices()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find info regarding your GPU with `!nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 29 23:01:45 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1060      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   62C    P8             10W /   78W |    1406MiB /   6144MiB |     30%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1980    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A      4284    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n",
      "|    0   N/A  N/A      4524    C+G   ...App\\OmenCommandCenterBackground.exe      N/A      |\n",
      "|    0   N/A  N/A      5896    C+G   ...dobe\\Adobe Animate 2021\\Animate.exe      N/A      |\n",
      "|    0   N/A  N/A      8984    C+G   ...\\DAUM\\PotPlayer\\PotPlayerMini64.exe      N/A      |\n",
      "|    0   N/A  N/A      9916    C+G   ...n\\131.0.2903.112\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     13960    C+G   ...6.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     18888    C+G   ...al\\Discord\\app-1.0.9173\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     20052    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     21108    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     22036    C+G   ...021\\CEPHtmlEngine\\CEPHtmlEngine.exe      N/A      |\n",
      "|    0   N/A  N/A     22980    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     28580    C+G   ...remium\\win64\\bin\\HarmonyPremium.exe      N/A      |\n",
      "|    0   N/A  N/A     30444    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     32728    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     35836    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     36520    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     36904    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     38504    C+G   ...soft Office\\root\\Office16\\EXCEL.EXE      N/A      |\n",
      "|    0   N/A  N/A     41812    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     41832    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     44220    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     53564    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise Time:\n",
    "\n",
    "1. Create a vector, scalar, matrix and tensor with values of your choosing using tf.constant().\n",
    "2. Find the shape, rank and size of the tensors you created in 1.\n",
    "3. Create two tensors containing random values between 0 and 1 with shape [5, 300].\n",
    "4. Multiply the two tensors you created in 3 using matrix multiplication.\n",
    "5. Multiply the two tensors you created in 3 using dot product.\n",
    "6. Create a tensor with random values between 0 and 1 with shape [224, 224, 3].\n",
    "7. Find the min and max values of the tensor you created in 6.\n",
    "8. Created a tensor with random values of shape [1, 224, 224, 3] then squeeze it to change the shape to [224, 224, 3].\n",
    "9. Create a tensor with shape [10] using your own choice of values, then find the index which has the maximum value.\n",
    "10. One-hot encode the tensor you created in 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1\n",
    "scalar = tf.constant(70)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tf.constant([1, 2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[3, 4],\n",
       "       [5, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tf.constant([[3,4],\n",
    "                      [5,6]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       "array([[[10, 20],\n",
       "        [30, 40]],\n",
       "\n",
       "       [[11, 22],\n",
       "        [33, 44]]], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([[[10,20],\n",
    "                       [30,40]],\n",
    "                       [[11,22],\n",
    "                       [33,44]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]),\n",
       " TensorShape([2]),\n",
       " TensorShape([2, 2]),\n",
       " TensorShape([2, 2, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2\n",
    "scalar.shape, vector.shape, matrix.shape, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=2>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=3>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(scalar), tf.rank(vector), tf.rank(matrix), tf.rank(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int32(1), np.int32(2), np.int32(4), np.int32(8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(scalar).numpy(), tf.size(vector).numpy(), tf.size(matrix).numpy(), tf.size(tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 300), dtype=float64, numpy=\n",
       " array([[0.79996396, 0.52318446, 0.18748098, ..., 0.84164263, 0.36373581,\n",
       "         0.6448981 ],\n",
       "        [0.59194398, 0.82549503, 0.95528895, ..., 0.46274718, 0.20646377,\n",
       "         0.21288059],\n",
       "        [0.85775223, 0.32515423, 0.44863049, ..., 0.39706708, 0.22056834,\n",
       "         0.34573619],\n",
       "        [0.61718291, 0.08334234, 0.39282044, ..., 0.71577625, 0.583205  ,\n",
       "         0.87658822],\n",
       "        [0.79597198, 0.40124205, 0.86456206, ..., 0.74309565, 0.67433257,\n",
       "         0.2128557 ]])>,\n",
       " <tf.Tensor: shape=(5, 300), dtype=float64, numpy=\n",
       " array([[0.29866785, 0.89096465, 0.17977047, ..., 0.78279121, 0.45629769,\n",
       "         0.85754862],\n",
       "        [0.82462624, 0.05751266, 0.83938867, ..., 0.76798208, 0.61105176,\n",
       "         0.07967464],\n",
       "        [0.97257552, 0.72587492, 0.99914081, ..., 0.07927233, 0.13682753,\n",
       "         0.69810842],\n",
       "        [0.58826884, 0.09078152, 0.07491041, ..., 0.4962493 , 0.18758016,\n",
       "         0.01094319],\n",
       "        [0.11854349, 0.46352853, 0.15372593, ..., 0.2249093 , 0.34278487,\n",
       "         0.55100348]])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3\n",
    "tensor1 = tf.constant(np.random.random([5, 300]))\n",
    "tensor2 = tf.constant(np.random.random([5, 300]))\n",
    "\n",
    "tensor1, tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 300), dtype=float64, numpy=\n",
       "array([[0.23892352, 0.46613885, 0.03370354, ..., 0.65883046, 0.16597181,\n",
       "        0.55303148],\n",
       "       [0.48813253, 0.04747642, 0.80185872, ..., 0.35538154, 0.12616005,\n",
       "        0.01696119],\n",
       "       [0.83422882, 0.2360213 , 0.44824503, ..., 0.03147643, 0.03017982,\n",
       "        0.24136134],\n",
       "       [0.36306948, 0.00756594, 0.02942634, ..., 0.35520346, 0.10939769,\n",
       "        0.00959267],\n",
       "       [0.0943573 , 0.18598714, 0.1329056 , ..., 0.16712913, 0.231151  ,\n",
       "        0.11728423]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 4\n",
    "result = tensor1 * tensor2\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float64, numpy=\n",
       "array([[72.30981098, 75.50588583, 73.48252169, 71.86139525, 78.78838429],\n",
       "       [71.54323424, 74.3869124 , 76.76940419, 74.03959575, 77.39483418],\n",
       "       [72.59833209, 74.97011183, 75.3803527 , 72.16246385, 74.32319731],\n",
       "       [67.21703465, 73.19693713, 66.31472193, 69.47054779, 69.22329379],\n",
       "       [72.24807616, 78.28668899, 74.20517949, 73.20410387, 78.74978938]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 5\n",
    "tensor1 @ tf.transpose(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(224, 224, 3), dtype=float64, numpy=\n",
       "array([[[0.6889541 , 0.17305598, 0.97795842],\n",
       "        [0.14369852, 0.13033119, 0.91988337],\n",
       "        [0.74345245, 0.67977389, 0.77476975],\n",
       "        ...,\n",
       "        [0.59367417, 0.99584037, 0.93725872],\n",
       "        [0.87229166, 0.8970433 , 0.66983146],\n",
       "        [0.78633408, 0.28153962, 0.64171979]],\n",
       "\n",
       "       [[0.19222755, 0.74718778, 0.06603275],\n",
       "        [0.82714114, 0.16598692, 0.42310519],\n",
       "        [0.53803203, 0.68914195, 0.09414146],\n",
       "        ...,\n",
       "        [0.69968675, 0.5049401 , 0.15663633],\n",
       "        [0.89616921, 0.94341304, 0.55241393],\n",
       "        [0.82165558, 0.6304075 , 0.07611324]],\n",
       "\n",
       "       [[0.30015334, 0.16433831, 0.52319256],\n",
       "        [0.69017942, 0.57231043, 0.38299878],\n",
       "        [0.60286582, 0.56218911, 0.9627808 ],\n",
       "        ...,\n",
       "        [0.8273599 , 0.16906943, 0.45210786],\n",
       "        [0.20994204, 0.83433648, 0.46244244],\n",
       "        [0.20675567, 0.66419667, 0.74982533]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.7524226 , 0.95527425, 0.44377609],\n",
       "        [0.76936718, 0.12380766, 0.86787357],\n",
       "        [0.79423783, 0.47533473, 0.58175791],\n",
       "        ...,\n",
       "        [0.80852197, 0.69112039, 0.67682344],\n",
       "        [0.35058122, 0.547492  , 0.82533614],\n",
       "        [0.21083499, 0.19208318, 0.72059991]],\n",
       "\n",
       "       [[0.82716721, 0.63238847, 0.74232925],\n",
       "        [0.64582518, 0.09934783, 0.01673393],\n",
       "        [0.51111207, 0.37574139, 0.38428407],\n",
       "        ...,\n",
       "        [0.30598541, 0.10196953, 0.13246315],\n",
       "        [0.60297674, 0.82347153, 0.47169012],\n",
       "        [0.38425426, 0.74826324, 0.17201899]],\n",
       "\n",
       "       [[0.49647082, 0.32605668, 0.9717265 ],\n",
       "        [0.31889478, 0.80149172, 0.83825828],\n",
       "        [0.11385657, 0.71617312, 0.83810417],\n",
       "        ...,\n",
       "        [0.1239305 , 0.58234081, 0.88636783],\n",
       "        [0.1562623 , 0.32915237, 0.528604  ],\n",
       "        [0.61653714, 0.4199482 , 0.52450616]]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 6\n",
    "tensor3 = tf.constant(np.random.random([224,224,3]))\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=3.099144085028094e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=0.9999906407866549>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 7\n",
    "tf.reduce_min(tensor3), tf.reduce_max(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 224, 224, 3), dtype=float64, numpy=\n",
       "array([[[[0.00939266, 0.27975762, 0.71827679],\n",
       "         [0.08894262, 0.26753247, 0.58705822],\n",
       "         [0.61610311, 0.26403068, 0.71245644],\n",
       "         ...,\n",
       "         [0.97710813, 0.00165777, 0.45119487],\n",
       "         [0.83878267, 0.43712768, 0.91458832],\n",
       "         [0.32766109, 0.88423251, 0.81354076]],\n",
       "\n",
       "        [[0.91144482, 0.02459742, 0.50308224],\n",
       "         [0.20052408, 0.20453454, 0.70665027],\n",
       "         [0.74788114, 0.08580635, 0.19384476],\n",
       "         ...,\n",
       "         [0.39945736, 0.31899759, 0.72232037],\n",
       "         [0.5789252 , 0.61959607, 0.474825  ],\n",
       "         [0.85404447, 0.37995542, 0.9300012 ]],\n",
       "\n",
       "        [[0.11014093, 0.29327816, 0.54847112],\n",
       "         [0.12290545, 0.07312398, 0.73941314],\n",
       "         [0.7616844 , 0.51641653, 0.62406008],\n",
       "         ...,\n",
       "         [0.85097793, 0.79080244, 0.27823159],\n",
       "         [0.27182723, 0.15493547, 0.25084947],\n",
       "         [0.40124003, 0.30687909, 0.89107455]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.32117546, 0.50413389, 0.62174468],\n",
       "         [0.32913416, 0.7242213 , 0.90542538],\n",
       "         [0.39532325, 0.21190894, 0.54780496],\n",
       "         ...,\n",
       "         [0.28487041, 0.03765214, 0.92868721],\n",
       "         [0.78666132, 0.4639111 , 0.08662324],\n",
       "         [0.29831794, 0.54400844, 0.67501174]],\n",
       "\n",
       "        [[0.3149108 , 0.79471518, 0.39217705],\n",
       "         [0.14765502, 0.96285051, 0.37562126],\n",
       "         [0.13503772, 0.12267589, 0.74217324],\n",
       "         ...,\n",
       "         [0.1664528 , 0.76070928, 0.81382028],\n",
       "         [0.2417182 , 0.24747693, 0.73021401],\n",
       "         [0.3118017 , 0.80298981, 0.53516513]],\n",
       "\n",
       "        [[0.56240032, 0.63459391, 0.42699464],\n",
       "         [0.46021283, 0.95848941, 0.22065301],\n",
       "         [0.12840778, 0.50849654, 0.29962078],\n",
       "         ...,\n",
       "         [0.37095391, 0.40259535, 0.40652499],\n",
       "         [0.08413967, 0.37075612, 0.05389521],\n",
       "         [0.72751393, 0.46272516, 0.37635092]]]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 8\n",
    "tensor4 = tf.constant(np.random.random([1,224,224,3]))\n",
    "tensor4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(224, 224, 3), dtype=float64, numpy=\n",
       "array([[[0.00939266, 0.27975762, 0.71827679],\n",
       "        [0.08894262, 0.26753247, 0.58705822],\n",
       "        [0.61610311, 0.26403068, 0.71245644],\n",
       "        ...,\n",
       "        [0.97710813, 0.00165777, 0.45119487],\n",
       "        [0.83878267, 0.43712768, 0.91458832],\n",
       "        [0.32766109, 0.88423251, 0.81354076]],\n",
       "\n",
       "       [[0.91144482, 0.02459742, 0.50308224],\n",
       "        [0.20052408, 0.20453454, 0.70665027],\n",
       "        [0.74788114, 0.08580635, 0.19384476],\n",
       "        ...,\n",
       "        [0.39945736, 0.31899759, 0.72232037],\n",
       "        [0.5789252 , 0.61959607, 0.474825  ],\n",
       "        [0.85404447, 0.37995542, 0.9300012 ]],\n",
       "\n",
       "       [[0.11014093, 0.29327816, 0.54847112],\n",
       "        [0.12290545, 0.07312398, 0.73941314],\n",
       "        [0.7616844 , 0.51641653, 0.62406008],\n",
       "        ...,\n",
       "        [0.85097793, 0.79080244, 0.27823159],\n",
       "        [0.27182723, 0.15493547, 0.25084947],\n",
       "        [0.40124003, 0.30687909, 0.89107455]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.32117546, 0.50413389, 0.62174468],\n",
       "        [0.32913416, 0.7242213 , 0.90542538],\n",
       "        [0.39532325, 0.21190894, 0.54780496],\n",
       "        ...,\n",
       "        [0.28487041, 0.03765214, 0.92868721],\n",
       "        [0.78666132, 0.4639111 , 0.08662324],\n",
       "        [0.29831794, 0.54400844, 0.67501174]],\n",
       "\n",
       "       [[0.3149108 , 0.79471518, 0.39217705],\n",
       "        [0.14765502, 0.96285051, 0.37562126],\n",
       "        [0.13503772, 0.12267589, 0.74217324],\n",
       "        ...,\n",
       "        [0.1664528 , 0.76070928, 0.81382028],\n",
       "        [0.2417182 , 0.24747693, 0.73021401],\n",
       "        [0.3118017 , 0.80298981, 0.53516513]],\n",
       "\n",
       "       [[0.56240032, 0.63459391, 0.42699464],\n",
       "        [0.46021283, 0.95848941, 0.22065301],\n",
       "        [0.12840778, 0.50849654, 0.29962078],\n",
       "        ...,\n",
       "        [0.37095391, 0.40259535, 0.40652499],\n",
       "        [0.08413967, 0.37075612, 0.05389521],\n",
       "        [0.72751393, 0.46272516, 0.37635092]]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 9\n",
    "tensor4_squeezed = tf.squeeze(tensor4)\n",
    "tensor4_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10]), np.int64(5))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 9\n",
    "a = tf.constant([1,4,6,3,7,9,2,6,8,4])\n",
    "a.shape, tf.argmax(a).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 10\n",
    "tf.one_hot(a, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
